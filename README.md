# ğŸ“ˆ Pipeline Batch Bovespa

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white) ![Terraform](https://img.shields.io/badge/terraform-%235835CC.svg?style=for-the-badge&logo=terraform&logoColor=white) ![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)

## ğŸ Getting Started

This data pipeline extracts, processes, and analyzes daily trading data from the B3 (Brasil, Bolsa, BalcÃ£o) stock exchange.
Raw data is collected from public sources using scheduled ingestion jobs and stored in AWS S3 in partitioned Parquet format. Processing and transformations are handled via AWS Glue jobs triggered by AWS Lambda functions. Processed data is made available for querying using Amazon Athena.

The official source for the raw trading data is: [https://sistemaswebb3-listados.b3.com.br/indexPage/day/IBOV?language=pt-br](https://sistemaswebb3-listados.b3.com.br/indexPage/day/IBOV?language=pt-br)

## ğŸ“ Project Structure

```
fiap_tech_challenge_fase_2/
â”œâ”€â”€ aws/                            # Local AWS credentials configuration
â”‚   â””â”€â”€ credentials                 # Credentials file copied from ~/.aws/credentials
â”œâ”€â”€ deploy/                         # Infrastructure as Code (IaC) using Terraform
â”‚   â”œâ”€â”€ athena/                     # Athena tables and query configurations
â”‚   â”œâ”€â”€ event_bridge/               # Scheduled rules and EventBridge configurations
â”‚   â”œâ”€â”€ glue_catalog_database/      # Glue Data Catalog and database definitions
â”‚   â”œâ”€â”€ lambda/                     # AWS Lambda functions (e.g., ETL trigger)
â”‚   â”œâ”€â”€ s3/                         # S3 bucket configuration
â”‚   â”œâ”€â”€ main.tf                     # Main Terraform configuration file
â”‚   â””â”€â”€ variables.tf                # Terraform variables definition
â”œâ”€â”€ docs/                           # Project documentation
â”œâ”€â”€ src/                            # Application source code
â”‚   â”œâ”€â”€ b3-trading-scraper/         # Scraper to extract data from B3 (stock exchange)
â”‚   â”‚   â”œâ”€â”€ handler.py              # Main function for scraping and ingestion
â”‚   â”‚   â””â”€â”€ requirements.txt        # Dependencies for the scraper
â”‚   â””â”€â”€ trigger-glue-etl/           # Lambda function to trigger the Glue ETL job
â”‚       â”œâ”€â”€ handler.py              # Main function to start the ETL
â”‚       â””â”€â”€ requirements.txt        # Dependencies for the Lambda function
â”œâ”€â”€ docker-compose.yml              # Docker service orchestration (for local setup)
â”œâ”€â”€ Dockerfile                      # Docker image definition (e.g., to run the scraper)
â””â”€â”€ Makefile                        # Utility commands for build, deployment, and setup
```

## ğŸ› ï¸ Tech Stack

- **Python 3.11+** 
- **Docker**  
- **Terraform**  
- **Makefile (for automation)**

## âš™ï¸ Installation

### ğŸ³ Install Docker